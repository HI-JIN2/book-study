
## 🧩 1. **추론 방식의 차이**

|구분|설명|예시|
|---|---|---|
|**연역 추론**|일반 → 구체|모든 인간은 죽는다. 소크라테스는 인간이다 → 소크라테스는 죽는다|
|**귀납 추론**|구체 → 일반|A, B 고양이 모두 수염이 있다 → 모든 고양이는 수염이 있다|

-------
## 🔍 2. **AI, ML, DL의 관계**

- **AI(인공지능)**: 인간의 사고를 모방하는 기술 전반 | 컴퓨터가 인간처럼 사고하고 판단하도록 만드는 기술
    
- **ML(머신러닝)**: AI 중 **데이터 기반 학습**을 통해 스스로 규칙을 찾음 | 컴퓨터에 인간의 학습능력과 같은 기능을 부여하는 기술
    
- **DL(딥러닝)**: 머신러닝 중 **인공신경망 기반 모델** 사용. 층이 깊음 | 인간 두뇌가 작동하는 방식을 기반으로 한 빅데이터 분석 기술을 구현

---
 
## 📚 3. 머신 러닝 -  **지도학습 vs 비지도학습**

- **지도학습**: 데이터 + 정답(label) → 분류(Classification), 회귀(Regression)
    
- **비지도학습**: 정답 없이 데이터 간 패턴 파악 → 클러스터링 등
    
- 데이터와 라벨이 있는지 여부가 핵심 차이!
    

---

## 🧾 4. **데이터 표현**

- **Sample(샘플)**: 하나의 데이터 포인트 (예: 수박 1개)
    
- **Feature(속성)**: 샘플의 특성 (색, 소리, 꼭지 모양 등)
    
- **Feature Value**: 각 특성의 구체적 값 (ex: 초록색, 말림, 청아)
    
- 데이터를 숫자로 변환 → **벡터** 형태 → 머신러닝 모델의 입력
    

---

## 🎯 5. **학습 목표와 오차**

- 목표: 실제 값 `y`와 예측 값 `ŷ`의 차이 줄이기
    
- 자주 쓰는 오차 지표:
    
    - **MSE (Mean Squared Error)**: 오차 제곱의 평균
        
    - **MAE (Mean Absolute Error)**: 오차의 절대값 평균
        
    - **RMSE**: MSE의 제곱근 (단위 맞춤용)
        
    - **MAPE**: 퍼센트 오차 기준
        

---

## ⚖️ 6. **Bias-Variance Trade-off**

|구분|설명|
|---|---|
|**Bias (편향)**|모델이 단순해서 학습이 부족한 상태 (Underfitting)|
|**Variance (분산)**|모델이 복잡해서 학습 데이터에만 너무 맞춤 (Overfitting)|

- 머신러닝의 핵심 과제: 둘의 균형 맞추기
    

---

## 🔧 7. **가설, 모델, 학습**

- **가설(Hypothesis)**: 데이터 → 예측을 위한 수식 형태
    
- **모델(Model)**: 가설 + 파라미터(예: β₀, β₁)
    
- **학습(Learning)**: 파라미터를 데이터 기반으로 조정하는 과정
    

---

## 📊 8. **데이터 분리**

- **Train Set**: 학습용 데이터
    
- **Validation Set**: 모델 구조 튜닝용
    
- **Test Set**: 최종 성능 평가용 (모델이 학습하지 않은 데이터)
    

---

## 🚨 9. **과적합 vs 과소적합**

|구분|설명|결과|
|---|---|---|
|**과소적합 (Underfitting)**|모델이 너무 단순|학습도 못함|
|**과적합 (Overfitting)**|모델이 너무 복잡|학습 데이터만 잘 맞추고 새로운 데이터는 못 맞춤|

---

## 🎯 10. **예측 불가능성과 노이즈**

- 실제 관측값 = 이상적인 함수값 + **노이즈**
    
- 노이즈는 줄일 수 없으며, 오차를 **Reducible** / **Irreducible** Error로 나눔
    
- **샘플 수 증가** → 관측 오차(분산) 감소 가능 → "빅데이터가 중요한 이유"
    

---

# 📝 시험 예상 문제

### ✅ **객관식**

1. 다음 중 귀납 추론의 예는?
    
    - A. 모든 고양이는 수염이 있다 → A는 고양이다 → A는 수염이 있다
        
    - B. A 고양이와 B 고양이 모두 수염이 있다 → 모든 고양이는 수염이 있다 ✅
        
2. 머신러닝 모델이 복잡하여 학습 데이터에만 잘 맞고 새로운 데이터엔 성능이 낮은 현상은?
    
    - A. Underfitting
        
    - B. Overfitting ✅
        
    - C. Noise
        
    - D. Generalization
        
3. 지도학습에서 반드시 필요한 것은?
    
    - A. 클러스터 수
        
    - B. 학습용 모델
        
    - C. 정답 라벨 ✅
        
    - D. 차원 축소
        
4. 다음 중 평가 지표가 아닌 것은?
    
    - A. MSE
        
    - B. MAE
        
    - C. RMSE
        
    - D. GBT ✅
        

---

### ✍️ **서술형**

1. 연역 추론과 귀납 추론의 차이를 예시와 함께 설명하시오.
    
2. Bias와 Variance가 높은 경우 각각 어떤 문제가 발생하는지, 이를 조절하는 방법은 무엇인지 설명하시오.
    
3. 머신러닝에서 오버피팅이 발생하는 이유와 방지 방법을 기술하시오.
    
4. 학습, 검증, 테스트 데이터셋의 역할을 각각 설명하시오.
    
5. MSE, RMSE, MAE, MAPE의 정의와 각각의 장단점을 비교하여 설명하시오.
    
